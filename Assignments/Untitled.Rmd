---
title: "STAC51 Assignment 1"
author: "Joseph Wang"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Question 1

## a)

The PMF is 

\begin{align*}
f_{\bar{Y}}(\bar{y}) = \frac{n!}{y_1! \dots y_k!} \pi_1^{y_1}\dots \pi_k^{y_k}
\end{align*}


Thus is the multivariate moment generating function is

\begin{align*}
M_{\bar{Y}}(\bar{t}) &= E(e^{\bar{t}^{'}\bar{y}})\\
&= \Sigma^n_{y_1}\Sigma^{n-y_1}_{y_2}\dots\Sigma^{n-y_1\dots -y_{k-1}}_{y_k}e^{t_1y_1 + \dots + t_ky_k} \frac{n!}{y_1! \dots y_k!} \pi_1^{y_1}\dots \pi_k^{y_k}\\
&= \Sigma^n_{y_1}\Sigma^{n-y_1}_{y_2}\dots\Sigma^{n-y_1\dots -y_{k-1}}_{y_k}\frac{n!}{y_1! \dots y_k!} (e^{t_1}\pi_1)^{y_1}\dots (e^{t_k}\pi_k)^{y_k}\\
&= (\Sigma^k_i e^{t_i}\pi_i)^n
\end{align*}

## b)

The moment generating function for the ith var is

\begin{align*}
M_{Y_i}(t) &= M_{\bar{Y}}(0,\dots,t,\dots,0)\\
&= (\pi_1 + \dots + e^t\pi_i + \dots  \pi_k)^n\\
\end{align*}

The mean is

\begin{align*}
E(Y_i) &= \frac{\partial}{\partial t} M_{Y_i}(0)\\
&= n(\pi_1 + \dots + e^t\pi_i + \dots  \pi_k)^{n-1}e^t\pi_i |_0\\
&= n\pi_i
\end{align*}

## c)

The second moment is 

\begin{align*}
E(Y_i^2) &= \frac{\partial^2}{\partial t^2} M_{Y_i}(0)\\
&= \frac{\partial}{\partial t} n(\pi_1 + \dots + e^t\pi_i + \dots  \pi_k)^{n-1}e^t\pi_i + e^t\pi_i*n(n-1)(\pi_1 + \dots + e^t\pi_i + \dots  \pi_k)^{n-2}e^t\pi_i |_0\\
&= n\pi_i+n^2\pi_i^2-n\pi_i^2
\end{align*}

The variance is

\begin{align*}
Var(Y_i) &= E(Y_i^2) - E(Y_i)^2\\
&= n\pi_i+n^2\pi_i^2-n\pi_i^2 - n^2\pi_i^2\\
&= n\pi_i(1-\pi_i)
\end{align*}

## d)

The joint moment generating function for the ith and jth var is

\begin{align*}
M_{Y_iY_j}(t_i,t_j) &= M_{\bar{Y}}(0,\dots,t_i,\dots, t_j,\dots,0)\\
&= (\pi_1 + \dots + e^{t_i}\pi_i + \dots + e^{t_j}\pi_j + \dots  \pi_k)^n\\
\end{align*}

The expected value of $Y_iY_j$ is

\begin{align*}
E(Y_iY_j) &= \frac{\partial^2}{\partial t_i t_j} M_{Y_iY_j}(0,0)\\
&= \frac{\partial}{\partial t_j} n(\pi_1 + \dots + e^{t_i}\pi_i + \dots + e^{t_j}\pi_j + \dots  \pi_k)^{n-1}e^{t_i}\pi_i|_0\\
&= n(n-1)(\pi_1 + \dots + e^{t_i}\pi_i + \dots + e^{t_j}\pi_j + \dots  \pi_k)^{n-2}e^{t_i}\pi_ie^{t_j}\pi_j|_0\\
&= n(n-1)\pi_i\pi_j
\end{align*}

The covariance of $Y_iY_j$ is

\begin{align*}
Cov(Y_i, Y_j) &= E(Y_iY_j) - E(Y_i)E(Y_j)\\
&= n(n-1)\pi_i\pi_j - n^2\pi_i\pi_j\\
&= -n\pi_i\pi_j
\end{align*}

## e)

Given $c=2$, $1 = \pi_i + \pi_j$

\begin{align*}
Cor(Y_i,Y_j) &= \frac{Cov(Y_i, Y_j)}{\sqrt{Var(Y_i)Var(Y_j)}}\\
&= \frac{-n\pi_i\pi_j}{\sqrt{n\pi_i(1-\pi_i)n\pi_j(1-\pi_j)}}\\
&= \frac{-\pi_i\pi_j}{\sqrt{\pi_i\pi_j(1-\pi_i-\pi_j+\pi_i\pi_j)}}\\
&= -1
\end{align*}

This makes sense as if the number of successes one category increases, the number of successes in the other category has to decrease. The change is 1:1 and thus has a linear relationship of factor 1.


# Question 2
```{r}
y = 5
n = 30
pihat = y/n
alpha = 0.1
```

## a)

Test P-values
```{r}
pi0 = 0.1
yfit = pi0*n

sewald= sqrt(pihat*(1-pihat)/n)
sescore = sqrt(pi0*(1-pi0)/n)

score = (pihat - pi0)/sescore

wald = (pihat - pi0)/sewald

lrt = 2*(y*log(y/yfit) + (n-y)*log((n-y)/(n-yfit)))


2*pnorm(score, lower.tail = FALSE)
2*pnorm(wald, lower.tail = FALSE)
pchisq(lrt,1,lower.tail = FALSE)
```

## b)
Wald CI
```{r}
z = qnorm(1-alpha/2)

c(pihat - z*sewald, pihat + z*sewald)
```

## c)
Score CI
```{r}
c(((n*pihat+z^2/2)-z*sqrt(n*pihat*(1-pihat)+z^2/4))/(n+z^2),((n*pihat+z^2/2)+z*sqrt(n*pihat*(1-pihat)+z^2/4))/(n+z^2))
```

## d)
Agresti-Coull
```{r}
pis = (y+z^2/2)/(n+z^2)
ns = n+z^2

c(pis-z*sqrt(pis*(1-pis)/ns), pis+z*sqrt(pis*(1-pis)/ns))
```

## e)

```{r}
prop.test(y,n,p=0.1, correct=F)
```


## f)

```{r}
library(binom)

binom.confint(x=y,n=n,conf.level=1-alpha, methods="all")
```

# Question 3

The likelihood function is $l(\theta|y) = {n \choose y} (\theta)^y (1-\theta)^{n-y}$. With n = 30 and y = 5.

## a)

Thus the likelihood under $\pi_0 = 0.1$ is

\begin{align*}
l(0.1|5) = {30 \choose 5} (0.1)^5 (0.9)^{25}
\end{align*}

```{r}
l0 = choose(n,y)*(pi0)^5*(1-pi0)^(n-y)
```


## b)

The MLE is the maximized likelihood over all possible values. $\hat{\pi} = \frac{y}{n} = \frac{5}{30} = \frac{1}{6}$.

\begin{align*}
l(\frac{1}{6}|5) = {30 \choose 5} (\frac{1}{6})^5 (\frac{1}{6})^{25}
\end{align*}

```{r}
l1 = choose(n,y)*(pihat)^5*(1-pihat)^(n-y)
```

## c)

```{r}
lrt2 = -2*log(l0/l1)
```


## d)

```{r}
qchisq(0.9, df=1)
```

## e)

```{r}
library(rootSolve)

f1 = function(pif){
  -2*(y*log(pif) + (n-y)*log(1-pif)-y*log(pihat) - (n-y)*log(1-pihat)) - qchisq(0.9, df=1)
}

uniroot.all(f=f1,interval=c(0,1))
```

# Question 4

```{r}
N = 100000
n = 25
pi = 0.06
count = 0
for(i in 1:N){
  z = rbinom(n,1,pi)
  y = sum(z)
  pi_hat = y/n
  
  l = pi_hat - 1.96*sqrt(pi_hat*(1-pi_hat)/n)
  t = pi_hat + 1.96*sqrt(pi_hat*(1-pi_hat)/n)
  
  if(l<= pi & pi <= t){
    count = count + 1
  }
}

count/N

```

# Question 6

```{r}
freq = c(229, 211, 93, 35, 7, 1)
sum(freq)
```

